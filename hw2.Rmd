---
title: "hw2"
author: "Kee-Young Shin"
date: "September 29, 2018"
output: github_document
---

## Problem 1
### Create subdirectory
```{r}
library(tidyverse)


dir.create("./hw2data")

```

```{r}

transit_data = read.csv("./hw2data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>% # clean name of data
  select(line:route11, entry, entrance_type, vending, ada) %>% # filter columns 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) %>% # convert character into logical
  unique()

transit_data
# The dataset contains information regarding NYC subway stations including, the line name,
# its location, its various routes, its entrance type, whether it has vending, whether it
# allows entry, and whether or not it is ADA compliant. I cleaned the dataset by converting # the names into snake case and taking out superfluous columns such as the coordinates for 
# the entrance. The new data set contained 684 rows and 19 columns. After the instructed  
# tidying process, the dataset is relatively tidy, but there is still room for improvement. # After selecing for certain columns, some rows were repeated. This was solved by using the unique function. 


dim(transit_data) # show rows and columns of data

 
transit_data %>%
  distinct(line, station_name)  # Count number of distinct stations
 
transit_data %>%
  distinct(line, station_name, ada) %>%
  summarize(sum(ada == "TRUE")) # Count how many stations are ADA compliant


transit_data %>%
	filter(vending == "NO") %>%  # show only entrances without vending 
  summarize(total = n(), yes = sum(entry == "TRUE")) %>% # find number of allowed entries
  mutate(prop = yes / total) # find proportion 


transit_data %>%
  gather(key = route_number, value = route_name, route1:route11) # reshaping data set

transit_data %>%
  gather(key = route_number, value = route_name, route1:route11) %>%
  filter(route_name == "A") %>% # filter by route A
  distinct(line, station_name) # show distinct lines 
# There are 60 distinct lines that serve the A train.

transit_data %>%
  gather(key = route_number, value = route_name, route1:route11) %>%
  filter(route_name == "A", ada == "TRUE") %>% # filter by route A and ADA compliance 
  distinct(line, station_name) # show distinct lines 
# Of the stations that serve the A train, 17 are ADA compliant. 


```

## Problem 2

```{r}
library(readxl)

wheel_data = read_excel("./hw2data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
	  sheet = 1, range = cell_cols("A:N")) %>%
	  janitor::clean_names() %>% # import data and clean names
    filter(!is.na(dumpster)) %>% # filter out non dumpster specific data 
    mutate(sports_balls = as.integer(round(sports_balls))) # rounding sports balls 
   
wheel_data

prcp_2017 = read_excel("./hw2data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
                       sheet = "2017 Precipitation", skip = 1 ) %>%  # import data
  janitor::clean_names() %>%  # clean name
  na.omit() %>% # remove na  
  mutate(year = 2017) # put in year column

prcp_2017

prcp_2016 = read_excel("./hw2data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
                       sheet = "2016 Precipitation", skip = 1 ) %>%  # import data 
  janitor::clean_names() %>%   # clean name
  na.omit() %>%  # remove na 
  mutate(year = 2016)  # put in year column 

prcp_2016

 
combined_prcp = bind_rows(prcp_2017, prcp_2016) %>%  # combine precipitation data 
    mutate(month = month.name[month]) # convert to character


combined_prcp

combined_prcp %>%
  filter(year == 2017) %>%
  summarize(total = sum(total))
combined_prcp %>%
  filter(year == 2016) %>%
  summarize(total = sum(total))
wheel_data %>%
  filter(year == 2016) %>%
  summarize(median = median(sports_balls))


filter(wheel_data, year == 2018) %>%
  summarize(sum(weight_tons))

```
There were `r nrow(combined_prcp)` and `r nrow(wheel_data)` observations for the precipitation data set and the trash wheel dataset, respectively. The total precipitation for 2017 was `r sum(prcp_2017$total)` and `r sum(prcp_2018$total)` for 2018. The median for precipitation for 2017 and 2018 were `r median(prcp_2017$total)` and `r median(prcp_2018$total)`, respectively. Some key variables for the trash dataset include the total trash weight in 2018 -- `r filter(wheel_data, year == 2018) %>% summarize(sum(weight_tons))` tons, median number of sports balls in 2017 -- `r wheel_data %>% filter(year == 2017) %>% summarize(median = median(sports_balls))` balls, and the mean of plastic bottles thrown out in 2018 -- `r filter(wheel_data, year == 2018) %>% summarize(mean(plastic_bottles))` bottles. Compare: aka precipitation of 2017 was smaller or larger


## Problem 3
```{r}
devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)

data("brfss_smart2010") # import data set 


filtered_brfss = brfss_smart2010 %>%
  janitor::clean_names() %>% # clean names 
  filter(topic == "Overall Health") %>%
  select(-class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>%
  spread(key = "response", value = "data_value") %>%  # making rows into columns
  janitor::clean_names() %>% # clean new columns 
  mutate(proportion_yv = excellent + very_good) %>% # create proportion column
  
filtered_brfss  

distinct(filtered_brfss, locationdesc) # distinct locations
# There are 404 distinct locations represented in this data set.
distinct(filtered_brfss, locationabbr) # distinct states
# All states are represented in addition to D.C.

filtered_brfss %>%
  group_by(locationabbr) %>%
  summarize(n = n()) %>% # take count of number of state
  arrange(-n) # put the count in descending order to show which state was observed most 
# New Jersey was observed most with 146 counts. 

filtered_brfss %>%
  filter(year == 2002) %>% # filter by year 2002
  summarize(median = median(excellent, na.rm = TRUE)) # show median for excellent

filtered_brfss %>%
  filter(year == 2002) %>% # filter by year 
  ggplot(aes(x = excellent)) + geom_histogram() # create histogram

filtered_brfss %>%
  filter(locationdesc %in% 
           c("NY - New York County", "NY - Queens County")) %>% # filter by location
  ggplot(aes(x = year, y = proportion_yv, color = locationdesc)) +
  geom_point() # create scatter plot



```


